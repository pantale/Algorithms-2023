{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2572666a-af91-498b-801f-14bd959d2606",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "Constitutive law identification with Artificial Neural Network\n",
    "(c) by Olivier Pantal√© 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce77105-421c-4c45-ac67-2fd129a79b36",
   "metadata": {},
   "source": [
    "## Notes of version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd309f-0999-460d-944d-30f211f0c2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-21T14:00:33.235565Z",
     "iopub.status.busy": "2023-09-21T14:00:33.234804Z",
     "iopub.status.idle": "2023-09-21T14:00:33.245213Z",
     "shell.execute_reply": "2023-09-21T14:00:33.243155Z",
     "shell.execute_reply.started": "2023-09-21T14:00:33.235494Z"
    }
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa99fb-33df-4068-96d9-9bf5e702d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Common.ipynb\n",
    "plotFigs = True\n",
    "saveFigs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f3c0f-099e-4e91-a581-3169f21cd5f5",
   "metadata": {},
   "source": [
    "# Import Data from the HF5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92211a43-3746-4241-9d7b-f84c85d6332e",
   "metadata": {},
   "source": [
    "Read Data from the HF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521b7eb-dfaf-4cf0-bdfa-d0b85cfb1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HF5 data file\n",
    "DataFile = '3Cr2Mo'\n",
    "#DataFile = 'JohnsonCook'\n",
    "data = readH5(filename = DataFile + '.h5')\n",
    "\n",
    "depsArray = getDepsparray(data)\n",
    "tempArray = getTarray(data)\n",
    "numberOfData = len(data)\n",
    "print('depsArray',depsArray,'contains',depsArray.shape[0],'data')\n",
    "print('tempArray',tempArray,'contains',tempArray.shape[0],'data')\n",
    "print('total of',numberOfData,'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71321ed-62cb-4b40-aa05-dae2380fa499",
   "metadata": {},
   "source": [
    "Plot the content of the data to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8019e-5d32-471e-8384-bdf8b7d70010",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (plotFigs):\n",
    "    plotDatas(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf6bd5-3f2e-41e8-ba03-1585eed2ca93",
   "metadata": {},
   "source": [
    "Assemble all data into one big chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4abcd5-4ef2-412b-8370-b54bc50eb3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeZero = False # Remove the first point where eps = 0\n",
    "\n",
    "first = True\n",
    "for d in data:\n",
    "    subdata = np.ones_like(d[2])*np.array([d[0],d[1]])\n",
    "    newdata = np.array([d[2][:,0], subdata[:,0], subdata[:,1], d[2][:,1]])\n",
    "    if first :\n",
    "        allData = newdata.T\n",
    "        first = False\n",
    "    else:\n",
    "        allData = np.concatenate((allData, newdata.T))\n",
    "print('Format of allData', allData.shape)\n",
    "if (removeZero): \n",
    "    identData = allData[allData[:,0] != 0]\n",
    "else:\n",
    "    identData = allData\n",
    "print('Format of identData', identData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45087ab-5b81-47fb-9e14-c75ca85d37e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-21T14:34:23.444895Z",
     "iopub.status.busy": "2023-09-21T14:34:23.442859Z",
     "iopub.status.idle": "2023-09-21T14:34:23.456825Z",
     "shell.execute_reply": "2023-09-21T14:34:23.454887Z",
     "shell.execute_reply.started": "2023-09-21T14:34:23.444811Z"
    }
   },
   "source": [
    "Compute the value of $\\dot\\varepsilon_0$ as the minimum value of the array $\\dot\\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400e0f8-3727-48d7-8589-fe3edb3010ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "deps0 = depsArray.min()\n",
    "print('deps0=',deps0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7f129-7714-45a1-9ec7-c76530eec53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-21T14:37:30.308849Z",
     "iopub.status.busy": "2023-09-21T14:37:30.307223Z",
     "iopub.status.idle": "2023-09-21T14:37:30.330956Z",
     "shell.execute_reply": "2023-09-21T14:37:30.327483Z",
     "shell.execute_reply.started": "2023-09-21T14:37:30.308770Z"
    }
   },
   "source": [
    "compute and replace $\\dot\\varepsilon$ by $\\log(\\frac{\\dot\\varepsilon}{\\dot\\varepsilon_0})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab658f8d-86a8-40f4-b3f8-67187a46c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "identData[:,1] = np.log(identData[:,1] / deps0)\n",
    "print('Data deps',depsArray)\n",
    "print('replaced by',np.unique(identData[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685aea72-aeda-4a66-b208-fa02b87cb306",
   "metadata": {},
   "source": [
    "Compute min and max of ranges\n",
    "\n",
    "Computes ANNdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872edfdb-7c97-40c8-aa42-1f9da10f83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "minData = identData.min(axis=0)\n",
    "maxData = identData.max(axis=0)\n",
    "rangeData = maxData - minData\n",
    "annData = (identData - minData) / rangeData\n",
    "print(\"Max error for normalized data is : %g\" %(annData * rangeData + minData - identData).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763f849-3a3f-484b-b742-e43ee0f6187c",
   "metadata": {},
   "source": [
    "Split Data into input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c746d3-f3d1-4140-ab38-3c185effd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "annInput = annData[:,0:3]\n",
    "annOutput = annData[:,3]\n",
    "annInput.shape, annOutput.shape\n",
    "nbInputs = 3\n",
    "nbOutputs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c073195-72c0-496e-b71d-7b0f1fc514eb",
   "metadata": {},
   "source": [
    "Define the structure of the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d9bbe-1619-4b6e-b35c-13e29d5d14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annTraining = True\n",
    "models = []\n",
    "convergences = []\n",
    "\n",
    "activations = ['sigmoid','tanh','relu','softplus','swish','exponential']\n",
    "shapes = [[17,9]]\n",
    "\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723120d7-6908-466d-b7b0-fc661f7416dc",
   "metadata": {},
   "source": [
    "Build the ANN or load data from previous Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b871f1f-93f3-45e1-90e1-daa5ead907e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation in activations:\n",
    "    for shape in shapes:\n",
    "        # Initialize a sequential model\n",
    "        model = Sequential()\n",
    "        name = str(nbInputs)\n",
    "        if type(shape) == list:\n",
    "            first = True\n",
    "            layNum = 0\n",
    "            for layer in shape:\n",
    "                if (first): \n",
    "                    model.add(Dense(layer, input_dim = nbInputs, activation = activation, name = 'hl-'+str(layNum)))\n",
    "                else:\n",
    "                    model.add(Dense(layer, activation = activation, name = 'hl-'+str(layNum)))\n",
    "                first = False\n",
    "                layNum += 1\n",
    "                name += '-' + str(layer)\n",
    "        else:\n",
    "            model.add(Dense(layer, input_dim = nbInputs, activation = activation))\n",
    "            name += '-' + str(layer)\n",
    "        model.add(Dense(nbOutputs, name = 'output'))\n",
    "        name += '-' + str(nbOutputs) + '-' + activation\n",
    "        model._name = name\n",
    "        models.append(model)\n",
    "        model.compile(loss = loss, optimizer = optimizer)   \n",
    "        convergences.append([name, np.array([])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ea370-61b6-4a47-bdc6-42e8f5c6bd17",
   "metadata": {},
   "source": [
    "Print summary of the Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c78d30-454c-42fa-93e3-9f478c773fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d494cde-3d0a-489f-a9cf-da9bceb56d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for convergence in convergences:\n",
    "    print(convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc969eb0-20a8-4e1b-b452-581d295aeeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-21T15:03:06.222359Z",
     "iopub.status.busy": "2023-09-21T15:03:06.220863Z",
     "iopub.status.idle": "2023-09-21T15:03:06.235925Z",
     "shell.execute_reply": "2023-09-21T15:03:06.232464Z",
     "shell.execute_reply.started": "2023-09-21T15:03:06.222286Z"
    }
   },
   "source": [
    "Train the new ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc64c2-71f1-46ba-b002-28129d43ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "maxIterations = 20\n",
    "savePeriod = 2\n",
    "skipRecordIterations = 1\n",
    "minLossReduction = 1e-8\n",
    "windowLength = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3776a-3fb1-4f6d-a2c1-ca3389c097c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annTraining = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9b927-c018-48e5-aa86-00d9cef6ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if annTraining:\n",
    "    for model, convergence in zip (models, convergences):\n",
    "        print(\"Start to train model :\", model.name)\n",
    "        iteration = 0\n",
    "        lastMeanLoss = 1\n",
    "        while(iteration < maxIterations):\n",
    "            history = model.fit(annInput, annOutput, epochs = epochs, use_multiprocessing = True, verbose = 0, shuffle = True)\n",
    "            loss = np.array(history.history['loss'])\n",
    "            meanLoss = loss.mean()\n",
    "            convergence[1] = np.append(convergence[1], loss)\n",
    "            iteration += 1\n",
    "            print('Iteration :', iteration, ': loss =', meanLoss, ': reduction =', lastMeanLoss - meanLoss)\n",
    "            lastMeanLoss = meanLoss\n",
    "            if (iteration % savePeriod):\n",
    "                # Save Tensorflow model\n",
    "                model.save(DataFile + '/' + model.name + '.h5')\n",
    "                # Save convergence data\n",
    "                writeArrayH5(DataFile + '/' + model.name + '-conv.h5', 'data', convergence[1])\n",
    "        print('End of tranning phase with %g iterations and %g loops' %(iteration, iteration*epochs))\n",
    "        # Save Tensorflow model\n",
    "        model.save(DataFile + '/' + model.name + '.h5')\n",
    "        # Save model manually\n",
    "        writeAnnH5(DataFile + '/' + model.name + '-ANN.h5')\n",
    "        # Save convergence data\n",
    "        writeArrayH5(DataFile + '/' + model.name + '-conv.h5', 'data', convergence[1])\n",
    "else:\n",
    "    for model, convergence in zip (models, convergences):\n",
    "        try:\n",
    "            # Load Tensorflow model\n",
    "            model.load_weights(DataFile + '/' + model.name + '.h5')\n",
    "            # Load convergence data\n",
    "            convergence[1] = readArrayH5(DataFile + '/' + model.name + '-conv.h5', 'data')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466b3f8-a941-43fd-8062-0eaacb2a70aa",
   "metadata": {},
   "source": [
    "Show the convergence curves filtered using the savgol filter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99851d8-9fa6-47b9-a688-6b8d22eb2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for convergence in convergences:\n",
    "    print('%s %.3f x 10-6' %(convergence[0], 1e6*np.mean(convergence[1][-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd7e9f-39f0-4c5d-8d11-a5641049cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for convergence in convergences:\n",
    "    try:\n",
    "        convergencef = savgol_filter(np.log10(convergence[1][epochs*skipRecordIterations:]), window_length = windowLength, polyorder = 2)\n",
    "        plt.plot(convergencef, label = convergence[0], linewidth=2)\n",
    "    except:\n",
    "        continue\n",
    "plt.ylim(None, -4)\n",
    "plt.xlabel(r'ANN training epoch', fontsize = 16)\n",
    "plt.ylabel(r'Training error : $\\log_{10}\\left(\\text{E}_\\text{MS}\\right)$', fontsize = 16)\n",
    "plt.title(r'Global convergence of the Artificial Neural Network models', fontsize = 16)\n",
    "plt.legend()\n",
    "if (saveFigs):\n",
    "    plt.savefig('Figures/' + DataFile + '-convergence.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbeeffe-4668-4227-a6a1-3f6cf16530b6",
   "metadata": {},
   "source": [
    "Show prediction of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db48f1b-c343-47c1-b36f-dae665ffe485",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEA = np.array([])\n",
    "EAARA = np.array([])\n",
    "for model in models:\n",
    "    ARstress = (model.predict(annInput, verbose=0)*rangeData[3]+minData[3]).flatten()\n",
    "    EAAR = np.sum(np.abs((identData[:,3] - ARstress)/(identData[:,3])))*100/ARstress.shape[0]\n",
    "    RMSE = np.sqrt(np.sum((identData[:,3] - ARstress)**2)/ARstress.shape[0])\n",
    "    RMSEA = np.append(RMSEA,RMSE)\n",
    "    EAARA = np.append(EAARA,EAAR)\n",
    "    print(\"Model %s\" %(model.name))\n",
    "    print('  RMSE = %.2f' %(RMSE)+' MPa')\n",
    "    print(\"  EAAR = %.2f\" %(EAAR) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3724c-d5c1-4719-bf75-86a93aeacaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRMSE = np.argsort(RMSEA)\n",
    "SEAAR = np.argsort(EAARA)\n",
    "for i in SRMSE:\n",
    "    print('model %s : RMSE=%.3f, ratio=%.3f' %(models[i].name,RMSEA[i],RMSEA[i]/RMSEA[SRMSE[0]]))\n",
    "print('--------------')\n",
    "for i in SEAAR:\n",
    "    print('model %s : EAAR=%.3f, ratio=%.3f' %(models[i].name,EAARA[i],EAARA[i]/EAARA[SEAAR[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5bdb3-7056-4a00-b627-70c074d43414",
   "metadata": {},
   "source": [
    "Function to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a5b5b-72e3-43f8-bf28-15af71c6e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResultsOfModel(model):\n",
    "    Ts = getTarray(data)\n",
    "    depsps = getDepsparray(data)\n",
    "    ndepsp = depsps.shape[0]\n",
    "    nT = Ts.shape[0]\n",
    "    \n",
    "    plt.figure(figsize = sbPlotSize(ndepsp))\n",
    "    plt.rc('text', usetex = True)\n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "    xs, ys = sbPlot(ndepsp)\n",
    "    idx = 1\n",
    "    for depsp in depsps:\n",
    "        plt.subplot(xs, ys, idx)\n",
    "        cl = 0\n",
    "        for T in Ts:\n",
    "            for d in data:\n",
    "                if (d[0] == depsp and d[1] == T):\n",
    "                    subdata = d[2]\n",
    "                    plt.plot(subdata[10::25,0], subdata[10::25,1], label=r'$T=' + str(d[1]) + '^{\\circ}C$', color=colors[cl], marker = 's', markersize = 5, linestyle = 'none')\n",
    "                    inp = np.zeros((subdata.shape[0],3))\n",
    "                    inp[:,0] = (subdata[:,0] - minData[0]) / rangeData[0]\n",
    "                    inp[:,1] = (np.log(depsp / deps0) - minData[1]) / rangeData[1]\n",
    "                    inp[:,2]  = (T - minData[2]) / rangeData[2]\n",
    "                    plt.plot(subdata[:,0],model.predict(inp, verbose=0)*rangeData[3]+minData[3],colors[cl], linewidth = 2.5)\n",
    "            cl += 1\n",
    "        plt.xlabel(r'strain $\\varepsilon$', fontsize = 16) # Labels the x axis\n",
    "        plt.ylabel(r'flow stress $\\sigma$ (MPa)', fontsize = 16) # Labels the y axis\n",
    "        plt.title(r'strain rate $\\dot{\\varepsilon} = ' + str(depsp) + '$ s$^{-1}$', fontsize = 16) # Self explicit command\n",
    "        plt.xlim(subdata[:,0].min(), subdata[:,0].max())\n",
    "        #plt.ylim(bottom=0)\n",
    "        idx += 1\n",
    "        \n",
    "    legendLines = []\n",
    "    cl = 0\n",
    "    for temp in list(Ts):\n",
    "        legendLines.append((r'$T=$' + str(int(temp)) + r'$^{\\circ}$C', {'color':colors[cl], 'linestyle':'-', 'linewidth':2.5, 'marker':'s'}))\n",
    "        cl += 1\n",
    "    \n",
    "    if (ndepsp % 2):\n",
    "        plt.legend([create_dummy_line(**l[1]) for l in legendLines], [l[0] for l in legendLines], \n",
    "               loc = 'upper center', fontsize = 12, ncols = 6, bbox_to_anchor = (1.0, -0.2), shadow = False)\n",
    "    else:\n",
    "        plt.legend([create_dummy_line(**l[1]) for l in legendLines], [l[0] for l in legendLines], \n",
    "               loc = 'upper center', fontsize = 12, ncols = 6, bbox_to_anchor = (0.0, -0.2), shadow = False)\n",
    "        \n",
    "    if (saveFigs):\n",
    "        plt.savefig('Figures/' + DataFile + '-' + model.name + '.svg')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b13306-1118-4dec-92c7-987472aa0ee4",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882c5c8-f6eb-49d0-8320-bb778d471d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (plotFigs):\n",
    "    for model in models:\n",
    "        print(model.name)\n",
    "        plotResultsOfModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea894a-4e02-4de3-88c6-200e5cf2fcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
